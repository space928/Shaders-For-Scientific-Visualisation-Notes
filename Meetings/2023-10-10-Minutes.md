# 2023-10-10 Meeting Minutes
_S153, Sir Alwyn Williams Building at 14:00_  
_Sederunt: Thomas Mathieson, Dr John Williamson_
## Last Week's Progress
 - The basics of the Jupyter Widget have been implemented based on the Jupyter Widget template on GitHub.
 - A basic rendering example using ModernGL (based on last week's work) has been integrated.
   - PNG streaming for the Jupyter Widget has been implemented
 - Thomas brings up the issue that OpenGL doesn't support multithreading
   - This is an issue as Jupyter cells ideally need to be able to run asynchronously. We also might want to be able to 
     spawn multiple rendering cells at once.
   - One solution could be to spawn a separate process for each OpenGL renderer
   - John thinks that could work
 - Thomas demonstrates a shader running in a Jupyter cell
   - Thomas explains that currently the frame updates are triggered using a bit of a hack relying on a callback from 
     the Jupyter widget.
   - And that there's currently a memory leak to track down.
 - Time has also been spent on general housekeeping and tidying up the code.
   - The GitHub issues/project have all been updated
   - The project is in a state where it is easy to replicate the current results.

## Questions
 - We continue our discussion on OpenGL threading:
   - Thomas suggests spawning a separate process for each OpenGL context, ie one per widget.
   - This would solve all problems relating to trying to share a single OpenGL context between cells, as OpenGL is 
     stateful which could make sharing a context without side effects difficult.
   - John asks whether or not we should even allow multiple contexts or not; we could only allow a single cell to be 
     active at once.
   - It might be painful trying to manage contexts having to be deactivated and reactivated.
 - Performance and latency testing still need to be done. PNG streaming seems to work absolutely fine on a reasonable 
   CPU, though it might struggle on lower end CPUs.
   - H.264 could still be a good option for this. Especially for internet transmission.
   - John suggests even MJPEG could be an option, it's easy to encode and quite small.
   - Hardware accelerated H.264 encoding seems to be vendor specific, so it might be the case that we implement a slow 
     generic encoder and one that binds to the library for NVIDIA GPUs running on Windows.
   - It might be complicated to do this in Python as ideally we don't want to be copying the framebuffer back to the 
     CPU just to encode it on the GPU.
 - John summarises the different modules to be worked on (see _Overall Schedule_)
   - He asks if Thomas is confident in being able to implement and test each of these modules.
   - Thomas brings up the potential complexity of supporting multiple graphics backends (OpenGL and WebGL) and how that 
     could be architected neatly.

## Next Week's Plan
 - Work towards H.264 streaming
 - Mouse/Keyboard interactivity
 - Latency testing
 - Start thinking about shader preprocessing
   - What are our needs (minimal and future)
   - How might we achieve this? Prototype?

## Overall Schedule
 - The plan is unchanged from last week, we're progressing nicely
 - John suggests that it's good to try and explore many of the ideas we plan on implementing early on to find out where 
   the pain points might be.
 - Thomas expressed concern about the fact that target demographic for this project is quite narrow (people who have 
   some experience with shaders and python and are interested in scientific visualisation).
   - John says this it's fine if it's a small evaluation if you can find a few expert users. But also if a gallery of 
     examples can be developed, that could help the evaluation. 
   - This is a concern for the second semester though.

_Meeting adjourned at 14:25_
